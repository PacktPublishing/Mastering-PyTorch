{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEwiZsE0kS03",
        "outputId": "d5a2e00c-e3d3-4d91-d477-aee7ed342853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x110db2b50>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZOT8-n-kS06"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torchtext import (data, datasets)\n",
        "# for recent version of torchtext\n",
        "# from torchtext.legacy import (data, datasets) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHVyQqELkS06"
      },
      "outputs": [],
      "source": [
        "TEXT_FIELD = data.Field(tokenize = data.get_tokenizer(\"basic_english\"), include_lengths = True)\n",
        "LABEL_FIELD = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_dataset, test_dataset = datasets.IMDB.splits(TEXT_FIELD, LABEL_FIELD)\n",
        "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(123))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1PrIPOtkS07"
      },
      "outputs": [],
      "source": [
        "MAX_VOCABULARY_SIZE = 25000\n",
        "\n",
        "TEXT_FIELD.build_vocab(train_dataset, \n",
        "                 max_size = MAX_VOCABULARY_SIZE)\n",
        "\n",
        "LABEL_FIELD.build_vocab(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywMIZXk3kS07"
      },
      "outputs": [],
      "source": [
        "B_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_data_iterator, valid_data_iterator, test_data_iterator = data.BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset, test_dataset), \n",
        "    batch_size = B_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po57izStkS08"
      },
      "outputs": [],
      "source": [
        "## If you are training using GPUs, we need to use the following function for the pack_padded_sequence method to work \n",
        "## (reference : https://discuss.pytorch.org/t/error-with-lengths-in-pack-padded-sequence/35517/3)\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence\n",
        "\n",
        "def cuda_pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True):\n",
        "    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
        "    lengths = lengths.cpu()\n",
        "    if enforce_sorted:\n",
        "      sorted_indices = None\n",
        "    else:\n",
        "      lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
        "      sorted_indices = sorted_indices.to(input.device)\n",
        "      batch_dim = 0 if batch_first else 1\n",
        "      input = input.index_select(batch_dim, sorted_indices)\n",
        "\n",
        "    data, batch_sizes = \\\n",
        "    torch._C._VariableFunctions._pack_padded_sequence(input, lengths, batch_first)\n",
        "    return PackedSequence(data, batch_sizes, sorted_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQk7kGQzkS09",
        "outputId": "870822fe-5113-4680-e91a-55684f52f22e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ashish.jha/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocabulary_size, embedding_dimension, hidden_dimension, output_dimension, dropout, pad_index):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension, padding_idx = pad_index)\n",
        "        self.lstm_layer = nn.LSTM(embedding_dimension, \n",
        "                           hidden_dimension, \n",
        "                           num_layers=1, \n",
        "                           bidirectional=True, \n",
        "                           dropout=dropout)\n",
        "        self.fc_layer = nn.Linear(hidden_dimension * 2, output_dimension)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, sequence, sequence_lengths=None):\n",
        "        if sequence_lengths is None:\n",
        "            sequence_lengths = torch.LongTensor([len(sequence)])\n",
        "        \n",
        "        # sequence := (sequence_length, batch_size)\n",
        "        embedded_output = self.dropout_layer(self.embedding_layer(sequence))\n",
        "        \n",
        "        \n",
        "        # embedded_output := (sequence_length, batch_size, embedding_dimension)\n",
        "        if torch.cuda.is_available():\n",
        "            packed_embedded_output = cuda_pack_padded_sequence(embedded_output, sequence_lengths)\n",
        "        else:\n",
        "            packed_embedded_output = nn.utils.rnn.pack_padded_sequence(embedded_output, sequence_lengths)\n",
        "        \n",
        "        packed_output, (hidden_state, cell_state) = self.lstm_layer(packed_embedded_output)\n",
        "        # hidden_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
        "        # cell_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
        "        \n",
        "        op, op_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # op := (sequence_length, batch_size, hidden_dimension * num_directions)\n",
        "        \n",
        "        hidden_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)        \n",
        "        # hidden_output := (batch_size, hidden_dimension * num_directions)\n",
        "        \n",
        "        return self.fc_layer(hidden_output)\n",
        "\n",
        "    \n",
        "INPUT_DIMENSION = len(TEXT_FIELD.vocab)\n",
        "EMBEDDING_DIMENSION = 100\n",
        "HIDDEN_DIMENSION = 32\n",
        "OUTPUT_DIMENSION = 1\n",
        "DROPOUT = 0.5\n",
        "PAD_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.pad_token]\n",
        "\n",
        "lstm_model = LSTM(INPUT_DIMENSION, \n",
        "            EMBEDDING_DIMENSION, \n",
        "            HIDDEN_DIMENSION, \n",
        "            OUTPUT_DIMENSION, \n",
        "            DROPOUT, \n",
        "            PAD_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFf06XI1kS0-"
      },
      "outputs": [],
      "source": [
        "UNK_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.unk_token]\n",
        "\n",
        "lstm_model.embedding_layer.weight.data[UNK_INDEX] = torch.zeros(EMBEDDING_DIMENSION)\n",
        "lstm_model.embedding_layer.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_DIMENSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVcmRuqUkS0_"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.Adam(lstm_model.parameters())\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "lstm_model = lstm_model.to(device)\n",
        "loss_func = loss_func.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95CQLqHMkS0_"
      },
      "outputs": [],
      "source": [
        "def accuracy_metric(predictions, ground_truth):\n",
        "    \"\"\"\n",
        "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
        "    \"\"\"\n",
        "    # round predictions to either 0 or 1\n",
        "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
        "    accuracy = success.sum() / len(success)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LWnLr6EkS1A"
      },
      "outputs": [],
      "source": [
        "def train(model, data_iterator, optim, loss_func):\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    model.train()\n",
        "    \n",
        "    for curr_batch in data_iterator:\n",
        "        optim.zero_grad()\n",
        "        sequence, sequence_lengths = curr_batch.text\n",
        "        preds = lstm_model(sequence, sequence_lengths).squeeze(1)\n",
        "        \n",
        "        loss_curr = loss_func(preds, curr_batch.label)\n",
        "        accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
        "        \n",
        "        loss_curr.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        loss += loss_curr.item()\n",
        "        accuracy += accuracy_curr.item()\n",
        "        \n",
        "    return loss/len(data_iterator), accuracy/len(data_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtjpA3SykS1A"
      },
      "outputs": [],
      "source": [
        "def validate(model, data_iterator, loss_func):\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for curr_batch in data_iterator:\n",
        "            sequence, sequence_lengths = curr_batch.text\n",
        "            preds = model(sequence, sequence_lengths).squeeze(1)\n",
        "            \n",
        "            loss_curr = loss_func(preds, curr_batch.label)\n",
        "            accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
        "\n",
        "            loss += loss_curr.item()\n",
        "            accuracy += accuracy_curr.item()\n",
        "        \n",
        "    return loss/len(data_iterator), accuracy/len(data_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jThtoDWBkS1A"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "for ep in range(num_epochs):\n",
        "\n",
        "    time_start = time.time()\n",
        "    \n",
        "    training_loss, train_accuracy = train(lstm_model, train_data_iterator, optim, loss_func)\n",
        "    validation_loss, validation_accuracy = validate(lstm_model, valid_data_iterator, loss_func)\n",
        "    \n",
        "    time_end = time.time()\n",
        "    time_delta = time_end - time_start \n",
        "    \n",
        "    if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        torch.save(lstm_model.state_dict(), 'lstm_model.pt')\n",
        "    \n",
        "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
        "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
        "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRRO3tm8kS1B",
        "outputId": "f1b229c1-3d36-49f2-8f75-f17f98dcd341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss: 0.585 | test accuracy: 76.19%\n"
          ]
        }
      ],
      "source": [
        "lstm_model.load_state_dict(torch.load('../../mastering_pytorch_packt/04_deep_recurrent_net_architectures/lstm_model.pt'))\n",
        "\n",
        "test_loss, test_accuracy = validate(lstm_model, test_data_iterator, loss_func)\n",
        "\n",
        "print(f'test loss: {test_loss:.3f} | test accuracy: {test_accuracy*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhPplHggkS1B"
      },
      "outputs": [],
      "source": [
        "def sentiment_inference(model, sentence):\n",
        "    model.eval()\n",
        "    \n",
        "    # text transformations\n",
        "    tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
        "    tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
        "    \n",
        "    # model inference\n",
        "    model_input = torch.LongTensor(tokenized).to(device)\n",
        "    model_input = model_input.unsqueeze(1)\n",
        "    \n",
        "    pred = torch.sigmoid(model(model_input))\n",
        "    \n",
        "    return pred.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "nd4b5SPgkS1C",
        "outputId": "d6c1f9d9-7198-4e70-8c98-5df473f753d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.06318538635969162\n",
            "0.015872443094849586\n",
            "0.37745001912117004\n",
            "0.8425034284591675\n",
            "0.9304025769233704\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_inference(lstm_model, \"This film is horrible\"))\n",
        "print(sentiment_inference(lstm_model, \"Director tried too hard but this film is bad\"))\n",
        "print(sentiment_inference(lstm_model, \"Decent movie, although could be shorter\"))\n",
        "print(sentiment_inference(lstm_model, \"This film will be houseful for weeks\"))\n",
        "print(sentiment_inference(lstm_model, \"I loved the movie, every part of it\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_N5H2ufkS1C"
      },
      "outputs": [],
      "source": [
        "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDlup9B1kS1C"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LCyghVTkS1D"
      },
      "outputs": [],
      "source": [
        "lig = LayerIntegratedGradients(lstm_model, lstm_model.embedding_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9oW_0FRkS1D"
      },
      "outputs": [],
      "source": [
        "def forward_with_sigmoid(input, l):\n",
        "    return torch.sigmoid(lstm_model(input, l))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i7aZfOJkS1D"
      },
      "outputs": [],
      "source": [
        "token_reference = TokenReferenceBase(reference_token_idx=PAD_INDEX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_FTWjVtkS1D"
      },
      "outputs": [],
      "source": [
        "# accumalate couple samples in this array for visualization purposes\n",
        "vis_data_records_ig = []\n",
        "\n",
        "def interpret_sentence(model, sentence, min_len = 7, label = 0):\n",
        "    # text transformations\n",
        "    tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
        "    tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
        "    \n",
        "    # model inference\n",
        "    model_input = torch.LongTensor(tokenized).to(device)\n",
        "    model_input = model_input.unsqueeze(1)\n",
        "    length_input = torch.LongTensor([len(tokenized)])\n",
        "    pred = torch.sigmoid(model(model_input, length_input))\n",
        "\n",
        "    # generate reference indices for each sample\n",
        "    reference_indices = token_reference.generate_reference(len(tokenized), device=device).unsqueeze(0)\n",
        "    \n",
        "    \n",
        "    print(model_input.shape)\n",
        "    print(reference_indices)\n",
        "    # compute attributions and approximation delta using layer integrated gradients\n",
        "    attributions_ig, delta = lig.attribute(model_input,\n",
        "                                           reference_indices.reshape(model_input.shape[1], model_input.shape[0]), \n",
        "                                           n_steps=500, return_convergence_delta=True)\n",
        "\n",
        "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
        "\n",
        "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
        "    \n",
        "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
        "    attributions = attributions.sum(dim=2).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    attributions = attributions.cpu().detach().numpy()\n",
        "\n",
        "    # storing couple samples in an array for visualization purposes\n",
        "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
        "                            attributions,\n",
        "                            pred,\n",
        "                            Label.vocab.itos[pred_ind],\n",
        "                            Label.vocab.itos[label],\n",
        "                            Label.vocab.itos[1],\n",
        "                            attributions.sum(),       \n",
        "                            text,\n",
        "                            delta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dmaThaJkS1E",
        "outputId": "98dcf3f2-eeb4-409b-a07f-878df3942a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1])\n",
            "tensor([[1, 1, 1, 1, 1, 1]])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected `len(lengths)` to be equal to batch_size, but got 1 (batch_size=6)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e9a78717adcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'It was a fantastic performance !'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best film ever'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Such a great show!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'It was a horrible movie'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I\\'ve never watched something as bad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-76a672ae7464>\u001b[0m in \u001b[0;36minterpret_sentence\u001b[0;34m(model, sentence, min_len, label)\u001b[0m\n\u001b[1;32m     22\u001b[0m     attributions_ig, delta = lig.attribute(model_input,\n\u001b[1;32m     23\u001b[0m                                            \u001b[0mreference_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                            n_steps=500, return_convergence_delta=True)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'('\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%.2f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', delta: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mattribute_to_layer_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattribute_to_layer_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         )\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/captum/attr/_utils/gradient.py\u001b[0m in \u001b[0;36m_forward_layer_eval\u001b[0;34m(forward_fn, inputs, layer, additional_forward_args, device_ids, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mgradient_neuron_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mattribute_to_layer_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattribute_to_layer_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/captum/attr/_utils/gradient.py\u001b[0m in \u001b[0;36m_forward_layer_eval_with_neuron_grads\u001b[0;34m(forward_fn, inputs, layer, additional_forward_args, gradient_neuron_index, device_ids, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mattribute_to_layer_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattribute_to_layer_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    363\u001b[0m     \u001b[0mdevice_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_device_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/captum/attr/_utils/gradient.py\u001b[0m in \u001b[0;36m_forward_layer_distributed_eval\u001b[0;34m(forward_fn, inputs, layer, target_ind, additional_forward_args, attribute_to_layer_input, forward_hook_with_return)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m     \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/captum/attr/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-2df3a5fea666>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence, sequence_lengths)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# embedded_output := (sequence_length, batch_size, embedding_dimension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpacked_embedded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embedded_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected `len(lengths)` to be equal to batch_size, but got 1 (batch_size=6)"
          ]
        }
      ],
      "source": [
        "interpret_sentence(lstm_model, 'It was a fantastic performance !', label=1)\n",
        "interpret_sentence(lstm_model, 'Best film ever', label=1)\n",
        "interpret_sentence(lstm_model, 'Such a great show!', label=1)\n",
        "interpret_sentence(lstm_model, 'It was a horrible movie', label=0)\n",
        "interpret_sentence(lstm_model, 'I\\'ve never watched something as bad', label=0)\n",
        "interpret_sentence(lstm_model, 'It is a disgusting movie!', label=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4056uuKkS1E"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "lstm.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}